
@inproceedings{jagannath_locomotion_2021,
	title = {Locomotion and {Path} {Planning} for {Roller} {Skating} {Dog} {Robot}},
	doi = {10.1109/INDIACom51348.2021.00120},
	abstract = {Bipeds and Quadrupeds take over the majority of leg inspired robots in the robotics industry; from complex path planning to complex algorithm design for purpose-built leg based robots, which are one of the major areas of research. Application-oriented robots and dynamic control of robots play an important role when coming to legged robots. Legged robots are incorporated recently in industrial inspection and surveillance. Due to highly flexible design and adaptive situation handling of various conditions, these robots are powerful in navigating and moving across the desired path. Presented here is a 4 legged dog robot that is designed around the Dynamixel ecosystem. The ecosystem not only gives us the flexibility to control the motors easily and robustly but also helps us to incorporate mathematical modeling and mathematical design of 4 legged robots. These actuators also give the flexibility of torque and speed control thus bringing additional dimensions to the motion planning. The robot dog structure is essentially designed to skate and glide over a flat surface; weight balancing and motion planning not only helps in handling and making the locomotion smoother, but also allows us to stabilize the bot at a much higher tolerance.},
	booktitle = {2021 8th {International} {Conference} on {Computing} for {Sustainable} {Global} {Development} ({INDIACom})},
	author = {Jagannath, Vivek and Sanil, Sahil and Kumar, Prabhat and Malhotra, Aman and Vighneswar, J. and Pethakar, Advay S and Sangeetha, M.},
	month = mar,
	year = {2021},
	keywords = {Dogs, Ecosystems, Industries, Legged locomotion, Legged Robots, Motion and Path Planning, Path planning, Service robots, Warehousing, Wheeled Robots},
	pages = {681--684},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\D2JBMJFD\\Jagannath et al. - 2021 - Locomotion and Path Planning for Roller Skating Do.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\UEXZJYXJ\\9441444.html:text/html},
}

@inproceedings{theodorou_reinforcement_2010,
	title = {Reinforcement learning of motor skills in high dimensions: {A} path integral approach},
	shorttitle = {Reinforcement learning of motor skills in high dimensions},
	doi = {10.1109/ROBOT.2010.5509336},
	abstract = {Reinforcement learning (RL) is one of the most general approaches to learning control. Its applicability to complex motor systems, however, has been largely impossible so far due to the computational difficulties that reinforcement learning encounters in high dimensional continuous state-action spaces. In this paper, we derive a novel approach to RL for parameterized control policies based on the framework of stochastic optimal control with path integrals. While solidly grounded in optimal control theory and estimation theory, the update equations for learning are surprisingly simple and have no danger of numerical instabilities as neither matrix inversions nor gradient learning rates are required. Empirical evaluations demonstrate significant performance improvements over gradient-based policy learning and scalability to high-dimensional control problems. Finally, a learning experiment on a robot dog illustrates the functionality of our algorithm in a real-world scenario. We believe that our new algorithm, Policy Improvement with Path Integrals (PI2), offers currently one of the most efficient, numerically robust, and easy to implement algorithms for RL in robotics.},
	booktitle = {2010 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	author = {Theodorou, Evangelos and Buchli, Jonas and Schaal, Stefan},
	month = may,
	year = {2010},
	note = {ISSN: 1050-4729},
	keywords = {Control systems, Function approximation, Inference algorithms, Integral equations, Learning systems, Optimal control, Robots, Scalability, Stochastic processes, Stochastic resonance},
	pages = {2397--2403},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\ZTSMHYVZ\\5509336.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\GAVPPPB8\\Theodorou et al. - 2010 - Reinforcement learning of motor skills in high dim.pdf:application/pdf},
}

@inproceedings{ullerstam_teaching_2004,
	title = {Teaching robots behavior patterns by using reinforcement learning: how to raise pet robots with a remote control},
	volume = {1},
	shorttitle = {Teaching robots behavior patterns by using reinforcement learning},
	abstract = {The goal of this project was to show that complex behavior patterns can be learnt by a system based on reinforcement learning. The specific task was to make AIBO, the Sony robot dog, learn complex behavior patterns based on interactions between humans and AIBO. The reinforcement learning system is taught by remote control, used by the human and connected to AIBO. To remember the learnt behavior sequences, a short-term memory of prior actions is used by AIBO. This paper demonstrates that it is possible to learn behavior sequences and the relationship of cause and effect in complex environments. The paper also shows that the system works in a natural environment, based on the interaction between humans and AIBO, learning the rewards and the means to reach them in parallel. AIBO is also able to pick up new behaviors instantly by using a method we call 'Instant learning'. The paper presents the methods for implementing such a system.},
	booktitle = {{SICE} 2004 {Annual} {Conference}},
	author = {Ullerstam, M. and Mizukawa, M.},
	month = aug,
	year = {2004},
	keywords = {Control systems, Content addressable storage, Education, Educational robots, Human robot interaction, Instruments, Laboratories, Machine learning, Positron emission tomography, Robot control},
	pages = {143--146 vol. 1},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\TVPWGYG5\\1491384.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\5YZPQDMZ\\Ullerstam and Mizukawa - 2004 - Teaching robots behavior patterns by using reinfor.pdf:application/pdf},
}

@inproceedings{singh_dog_2013,
	title = {A dog tail for communicating robotic states},
	doi = {10.1109/HRI.2013.6483625},
	abstract = {We present a dog-tail interface for communicating abstract affective robotic states. We believe that people have a passing knowledge to understand basic dog tail language (e.g., tail wagging means happy). This knowledge can be leveraged to understand affective states of a robot. For example, by appearing energetic, it can suggest that it has a full battery and does not need charging. To investigate this, we built a robotic tail interface to communicate affective states of a robot. We conducted an exploratory user study to explore how low-level tail parameters such as speed influence people's perceptions of affect. In this paper, we briefly describe our study design and the results obtained.},
	booktitle = {2013 8th {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction} ({HRI})},
	author = {Singh, Ashish and Young, James E.},
	month = mar,
	year = {2013},
	note = {ISSN: 2167-2148},
	keywords = {Robots, affective computing, Affective computing, animal-inspired interfaces, Animals, Computer science, Educational institutions, human-robot interaction, Human-robot interaction, Psychology},
	pages = {417--417},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\DDIIU4Q5\\Singh and Young - 2013 - A dog tail for communicating robotic states.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\BQ2AHQTG\\6483625.html:text/html},
}

@inproceedings{kitano_sony_1998,
	title = {Sony legged robot for {RoboCup} challenge},
	volume = {3},
	doi = {10.1109/ROBOT.1998.680735},
	abstract = {One of the ultimate dreams in robotics is to create life-like robotics systems, such as a humanoid robot and an animal-like legged robot. We choose to build a pet-type legged robot because we believe that dog-like and cat-like legged robots have major potential for future entertainment robotics markets for personal robots. However, a number of challenges exist before any such robot can be fielded in the real world. Robots have to be reasonably intelligent, maintain a certain level of agility, and be able to engage in some collaborative behaviors. RoboCup is an ideal challenge to foster robotics technologies for small personal and mobile robotics system. In this paper, we present Sony's legged robots system which entered RoboCup-98 Paris as a special exhibition game.},
	booktitle = {Proceedings. 1998 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({Cat}. {No}.{98CH36146})},
	author = {Kitano, H. and Fujita, M. and Zrehen, S. and Kageyama, K.},
	month = may,
	year = {1998},
	note = {ISSN: 1050-4729},
	keywords = {Dogs, Legged locomotion, Service robots, Control systems, Laboratories, Computer science, Humanoid robots, Intelligent robots, Mobile robots, Robot sensing systems},
	pages = {2605--2612 vol.3},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\SLYK7EIM\\Kitano et al. - 1998 - Sony legged robot for RoboCup challenge.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\4FIWMJLB\\680735.html:text/html},
}

@inproceedings{gatzoulis_adaptive_2006,
	title = {Adaptive {Social} {Skills} for {Robots} {Interacting} with {Virtual} {Characters} in {Real} {Worlds}},
	doi = {10.1109/ROMAN.2006.314387},
	abstract = {We propose the implementation of a new interaction type that allows the creation of adaptive social relationships between robots and virtual characters in a real world environment, using reinforcement learning. We present the implementation of a storytelling scenario, which results in an immersion experience for the robot. The robot is able to interact and learn dynamically from the virtual character},
	booktitle = {{ROMAN} 2006 - {The} 15th {IEEE} {International} {Symposium} on {Robot} and {Human} {Interactive} {Communication}},
	author = {Gatzoulis, C. and Sourgoutsidis, A. and Hurmusiadis, V. and Tang, W.},
	month = sep,
	year = {2006},
	note = {ISSN: 1944-9437},
	keywords = {Dogs, Human robot interaction, Positron emission tomography, Intelligent robots, Application software, Avatars, Cities and towns, Collaboration, Robotics and automation, Virtual reality},
	pages = {8--13},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\KLGDVS44\\Gatzoulis et al. - 2006 - Adaptive Social Skills for Robots Interacting with.pdf:application/pdf},
}

@inproceedings{singh_real-time_2006,
	title = {A {Real}-{Time} {Framework} for {Vision} based {Human} {Robot} {Interaction}},
	doi = {10.1109/IROS.2006.282397},
	abstract = {Interactive mobile robots are an active area of research. This paper presents a framework for designing a real-time vision based hand-body dynamic gesture recognition system for such robots. The said framework works in real world lighting conditions with complex backgrounds, and can handle intermittent motion of the camera. We present here a novel way in which the motion history image (MHI) and the motion energy image (MEI) is built. We propose a robust combining of the motion and color cues and we call this image as motion color image (MCI). The input signal is captured by using monocular color camera. Vision is the only feedback sensor being used. It is assumed that the gesturer is wearing clothes that are slightly different from the background. Gestures are first learned offline and then matched to the temporal data generated online in real time. We have tested this on a gesture database consisting of 11 hand-body gestures and have recorded recognition accuracy up to 90\%. We have partially implemented and testing the system for Sony's Aibo robot dog using remote framework (RFW) SDK by Sony},
	booktitle = {2006 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}},
	author = {Singh, Randeep and Seth, Bhartendu and Desai, Uday},
	month = oct,
	year = {2006},
	note = {ISSN: 2153-0866},
	keywords = {Cameras, Human robot interaction, Mobile robots, Color, Feedback, History, Real time systems, Robot vision systems, Robustness, Testing},
	pages = {5831--5836},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\ZA3QKTWR\\Singh et al. - 2006 - A Real-Time Framework for Vision based Human Robot.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\KSVYDDA5\\4058395.html:text/html},
}

@inproceedings{seiji_training_2004,
	title = {Training {AIBO} like a dog - preliminary results},
	doi = {10.1109/ROMAN.2004.1374799},
	abstract = {This work describes a method to facilitate human adaptation to a pet robot. A pet robot learns which behavior it could execute when stimulus are given and a human user learns how to give commands to the robot through its various sensors. A pet robot utilizes a computational classical conditioning model for learning to interpret human's commands. We propose and implement such a mutual adaptation framework, and develop like-dog heuristics to facilitate the human's adaptation to a pet robot AIBO. Finally we evaluate the heuristics through preliminary experiments.},
	booktitle = {{RO}-{MAN} 2004. 13th {IEEE} {International} {Workshop} on {Robot} and {Human} {Interactive} {Communication} ({IEEE} {Catalog} {No}.{04TH8759})},
	author = {Seiji, Y. and Tomohiro, Y.},
	month = sep,
	year = {2004},
	keywords = {Educational robots, Human robot interaction, Positron emission tomography, Educational institutions, Humanoid robots, Robot sensing systems, Algorithm design and analysis, Informatics, Tactile sensors, Temperature sensors},
	pages = {431--436},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\EC5IGNF6\\Seiji and Tomohiro - 2004 - Training AIBO like a dog - preliminary results.pdf:application/pdf},
}

@inproceedings{seiji_training_2004-1,
	title = {Training {AIBO} like a dog - preliminary results},
	doi = {10.1109/ROMAN.2004.1374799},
	abstract = {This work describes a method to facilitate human adaptation to a pet robot. A pet robot learns which behavior it could execute when stimulus are given and a human user learns how to give commands to the robot through its various sensors. A pet robot utilizes a computational classical conditioning model for learning to interpret human's commands. We propose and implement such a mutual adaptation framework, and develop like-dog heuristics to facilitate the human's adaptation to a pet robot AIBO. Finally we evaluate the heuristics through preliminary experiments.},
	booktitle = {{RO}-{MAN} 2004. 13th {IEEE} {International} {Workshop} on {Robot} and {Human} {Interactive} {Communication} ({IEEE} {Catalog} {No}.{04TH8759})},
	author = {Seiji, Y. and Tomohiro, Y.},
	month = sep,
	year = {2004},
	keywords = {Educational robots, Human robot interaction, Positron emission tomography, Educational institutions, Humanoid robots, Robot sensing systems, Algorithm design and analysis, Informatics, Tactile sensors, Temperature sensors},
	pages = {431--436},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\887HX54E\\1374799.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\6CREK8AK\\Seiji and Tomohiro - 2004 - Training AIBO like a dog - preliminary results.pdf:application/pdf},
}

@inproceedings{morita_4-legged_2006,
	title = {4-{Legged} {Mechanism} of {Realizing} {Dynamic} {Running}. - {Comparison} of {Movement} {Performance} by {Change} of {Locomotion} {Pattern}},
	doi = {10.1109/ICMA.2006.257571},
	abstract = {This paper discusses the possibility to realize both of walking and running by a single robot, which is made by the combination mechanism of linkages and actuators. This linkage mechanism have actuators below the number of joint, therefore it enables to reduce the weight of the robot. This study aims at realizing the 4-legged locomotion by controlling the phase to manipulate the legs made by linkage mechanism. This paper firstly shows the similarity of walking and running of 4-legged animal, and proposes the way of realizing the both actions by the change of phase of motion. In order to design the leg mechanism with effective linkage systems, the kinematics simulator was developed and the performance of the prototype was tested},
	booktitle = {2006 {International} {Conference} on {Mechatronics} and {Automation}},
	author = {Morita, Kazuo and Ishihara, Hidenori},
	month = jun,
	year = {2006},
	note = {ISSN: 2152-744X},
	keywords = {Legged locomotion, Intelligent robots, Mobile robots, 4-legged Locomotion, Animal structures, Control by Phase Declination, Couplings, Intelligent actuators, Leg, Mechatronics, Modeling, Stability},
	pages = {423--428},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\DPRR4SCR\\Morita and Ishihara - 2006 - 4-Legged Mechanism of Realizing Dynamic Running. -.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\4IGIDGE7\\4026120.html:text/html},
}

@article{werfel_embodied_nodate,
	title = {Embodied {Teachable} {Agents}: {Learning} by {Teaching} {Robots}},
	abstract = {Robots have an untapped potential to contribute to education by acting as subordinate learners for students to teach. The beneﬁts that the act of teaching provides for one’s own learning have long been recognized; tutoring-associated improvements in measures like achievement scores, depth of understanding, and motivation are often far greater for the tutor than the tutee. Artiﬁcial agents can help students reap these beneﬁts by providing surrogate pupils for them to teach, with potential advantages over human tutees. Robots have been observed to be more eﬀective and compelling than virtual agents in a variety of contexts. However, research on teachable agents for education has been limited to virtual agents, while research on humans teaching robots has been concerned with learning for the beneﬁt of the robot rather than that of the human. A new research direction exploring robots as teachable agents will lead to widespread beneﬁts in education, and open new possibilities enabled by physical embodiment.},
	language = {en},
	author = {Werfel, Justin},
	pages = {8},
	file = {Werfel - Embodied Teachable Agents Learning by Teaching Ro.pdf:C\:\\Users\\sawye\\Zotero\\storage\\EAL4Y4BL\\Werfel - Embodied Teachable Agents Learning by Teaching Ro.pdf:application/pdf},
}

@inproceedings{tanaka_learning_2012,
	address = {New York, NY, USA},
	series = {{HRI} '12},
	title = {Learning verbs by teaching a care-receiving robot by children: an experimental report},
	isbn = {978-1-4503-1063-5},
	shorttitle = {Learning verbs by teaching a care-receiving robot by children},
	url = {https://doi.org/10.1145/2157689.2157781},
	doi = {10.1145/2157689.2157781},
	abstract = {We investigate the use of care-receiving robot (CRR) for the purpose of supporting childhood education. In contrast to the conventional teaching agents that are designed to play the role of human teachers or caregivers, the robot here receives cares from children. We hypothesize that by using this CRR, we may construct a new educational framework whose goal is to promote children's spontaneous learning by teaching through teaching the CRR. The paper describes an experiment for investigating whether a CRR can promote children's learning English verbs through teaching it.},
	urldate = {2021-10-05},
	booktitle = {Proceedings of the seventh annual {ACM}/{IEEE} international conference on {Human}-{Robot} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Tanaka, Fumihide and Matsuzoe, Shizuko},
	month = mar,
	year = {2012},
	keywords = {care-receiving robot, child education, child-robot interaction, crr, direct teaching, learning by teaching, learning reinforcement, learning support, robot ethics},
	pages = {253--254},
	file = {Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\MYID2368\\Tanaka and Matsuzoe - 2012 - Learning verbs by teaching a care-receiving robot .pdf:application/pdf},
}

@inproceedings{hood_when_2015,
	address = {New York, NY, USA},
	series = {{HRI} '15},
	title = {When {Children} {Teach} a {Robot} to {Write}: {An} {Autonomous} {Teachable} {Humanoid} {Which} {Uses} {Simulated} {Handwriting}},
	isbn = {978-1-4503-2883-8},
	shorttitle = {When {Children} {Teach} a {Robot} to {Write}},
	url = {https://doi.org/10.1145/2696454.2696479},
	doi = {10.1145/2696454.2696479},
	abstract = {This article presents a novel robotic partner which children can teach handwriting. The system relies on the learning by teaching paradigm to build an interaction, so as to stimulate meta-cognition, empathy and increased self-esteem in the child user. We hypothesise that use of a humanoid robot in such a system could not just engage an unmotivated student, but could also present the opportunity for children to experience physically-induced benefits encountered during human-led handwriting interventions, such as motor mimicry. By leveraging simulated handwriting on a synchronised tablet display, a NAO humanoid robot with limited fine motor capabilities has been configured as a suitably embodied handwriting partner. Statistical shape models derived from principal component analysis of a dataset of adult-written letter trajectories allow the robot to draw purposefully deformed letters. By incorporating feedback from user demonstrations, the system is then able to learn the optimal parameters for the appropriate shape models. Preliminary in situ studies have been conducted with primary school classes to obtain insight into children's use of the novel system. Children aged 6-8 successfully engaged with the robot and improved its writing to a level which they were satisfied with. The validation of the interaction represents a significant step towards an innovative use for robotics which addresses a widespread and socially meaningful challenge in education.},
	urldate = {2021-10-05},
	booktitle = {Proceedings of the {Tenth} {Annual} {ACM}/{IEEE} {International} {Conference} on {Human}-{Robot} {Interaction}},
	publisher = {Association for Computing Machinery},
	author = {Hood, Deanna and Lemaignan, Séverin and Dillenbourg, Pierre},
	month = mar,
	year = {2015},
	keywords = {human-robot interaction, learning by teaching, education},
	pages = {83--90},
	file = {Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\8XUTFQQ3\\Hood et al. - 2015 - When Children Teach a Robot to Write An Autonomou.pdf:application/pdf},
}

@inproceedings{wang_new_2007,
	title = {A {New} {Remote}-controlled {Animal} {Robot} {Training} {System}},
	doi = {10.1109/ICITECHNOLOGY.2007.4290388},
	abstract = {This paper presents a new scatheless platform for training remote-controlled animal robot, which can be used to analyze the relations between electrical stimulation and animal behavior. It will not only provide a convenient platform and method to research the controllability of animal behavior and the possibility of training animal robots, but also open new possibilities for biomedical, artificial intelligence and cognitive science researches. This system consists of two parts: 1) multichannel remote-controlled stimulator backed by animal; 2) computer vision based animal motion-analysis system. The training results showed that the platform works accurately even under interference conditions.},
	booktitle = {2007 {IEEE} {International} {Conference} on {Integration} {Technology}},
	author = {Wang, Yongling and Yuan, Kui and Li, Jianfeng and Song, Weiguo},
	month = mar,
	year = {2007},
	keywords = {Intelligent robots, Robot sensing systems, Robotics and automation, Animal behavior, Animal robot, Artificial intelligence, Brain machine interface, Cognitive robotics, Cognitive science, Electrical stimulation, Machine intelligence, Technological innovation, Vision tracking},
	pages = {599--602},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\8N9WX4D6\\4290388.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\4UUGJ6TA\\Wang et al. - 2007 - A New Remote-controlled Animal Robot Training Syst.pdf:application/pdf},
}

@article{lakatos_dogs_2017,
	title = {Dogs as {Behavior} {Models} for {Companion} {Robots}: {How} {Can} {Human}–{Dog} {Interactions} {Assist} {Social} {Robotics}?},
	volume = {9},
	issn = {2379-8939},
	shorttitle = {Dogs as {Behavior} {Models} for {Companion} {Robots}},
	doi = {10.1109/TCDS.2016.2552244},
	abstract = {This position paper (re)presents a relatively new approach for the behavioral design of companion robots, the use of dogs' behavior as a model. This paper discusses the advantages of this approach compared to other prevalent approaches in the field of social robotics and analyzes its effectiveness through the review of three different experimental studies utilizing this concept.},
	number = {3},
	journal = {IEEE Transactions on Cognitive and Developmental Systems},
	author = {Lakatos, Gabriella},
	month = sep,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Cognitive and Developmental Systems},
	keywords = {Dogs, Robots, Human-robot interaction, Antennas, Auditory system, Emotion attribution, Emotion recognition, human–dog interactions, human–robot interactions, intention recognition},
	pages = {234--240},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\PS6GV6AA\\7450176.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\CVX49Z78\\Lakatos - 2017 - Dogs as Behavior Models for Companion Robots How .pdf:application/pdf},
}

@inproceedings{loftin_learning_2014,
	title = {Learning something from nothing: {Leveraging} implicit human feedback strategies},
	shorttitle = {Learning something from nothing},
	doi = {10.1109/ROMAN.2014.6926319},
	abstract = {In order to be useful in real-world situations, it is critical to allow non-technical users to train robots. Existing work has considered the problem of a robot or virtual agent learning behaviors from evaluative feedback provided by a human trainer. That work, however, has treated feedback as a numeric reward that the agent seeks to maximize, and has assumed that all trainers will provide feedback in the same way when teaching the same behavior. We report the results of a series of user studies that indicate human trainers use a variety of approaches to providing feedback in practice, which we describe as different “training strategies.” For example, users may not always give explicit feedback in response to an action, and may be more likely to provide explicit reward than explicit punishment, or vice versa. If the trainer is consistent in their strategy, then it may be possible to infer knowledge about the desired behavior from cases where no explicit feedback is provided. We discuss a probabilistic model of human-provided feedback that can be used to classify these different training strategies based on when the trainer chooses to provide explicit reward and/or explicit punishment, and when they choose to provide no feedback. Additionally, we investigate how training strategies may change in response to the appearance of the learning agent. Ultimately, based on this work, we argue that learning agents designed to understand and adapt to different users' training strategies will allow more efficient and intuitive learning experiences.},
	booktitle = {The 23rd {IEEE} {International} {Symposium} on {Robot} and {Human} {Interactive} {Communication}},
	author = {Loftin, Robert and Peng, Bei and MacGlashan, James and Littman, Michael L. and Taylor, Matthew E. and Huang, Jeff and Roberts, David L.},
	month = aug,
	year = {2014},
	note = {ISSN: 1944-9437},
	keywords = {Dogs, Robots, Computer science, Probabilistic logic, Sprites (computer), Training},
	pages = {607--612},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\8EK5EUJS\\6926319.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\TGGVPVPU\\Loftin et al. - 2014 - Learning something from nothing Leveraging implic.pdf:application/pdf},
}

@inproceedings{maeda_differential_2008,
	title = {Differential reinforcement-type shaping {Q}-{Learning} method based on animal training for autonomous mobile robot},
	doi = {10.1109/FUZZY.2008.4630654},
	abstract = {The general idea of ldquoshapingrdquo used by ethology, behavior analysis or animal training is a remarkable method. ldquoShapingrdquo is a general idea that the learner is given a reinforcement signal step by step gradually and inductively forward the behavior from easy tasks to complicated tasks. In this paper, we propose a shaping reinforcement learning method took in a general idea of shaping to the reinforcement learning that can acquire a desired behavior by the repeated search autonomously. Three different shaping reinforcement learning methods used Q-learning, profit sharing, and actor-critic to check the efficiency of the shaping were proposed at first. Furthermore, we proposed the differential reinforcement-type shaping Q-learning (DR-SQL) applied a general idea of ldquodifferential reinforcementrdquo to reinforce a special behavior step by step such as real animal training, and confirmed the effectiveness of these methods by the simulation experiment of grid search problem.},
	booktitle = {2008 {IEEE} {International} {Conference} on {Fuzzy} {Systems} ({IEEE} {World} {Congress} on {Computational} {Intelligence})},
	author = {Maeda, Yoichiro and Hanaka, Satoshi},
	month = jun,
	year = {2008},
	note = {ISSN: 1098-7584},
	keywords = {Robots, Animals, Training, Conferences, Dolphins, Humans, Learning},
	pages = {2066--2071},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\sawye\\Zotero\\storage\\LL8RDLUZ\\4630654.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\sawye\\Zotero\\storage\\WBCQTMQ9\\Maeda and Hanaka - 2008 - Differential reinforcement-type shaping Q-Learning.pdf:application/pdf},
}
